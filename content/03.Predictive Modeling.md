## Predictive Modeling {.page_break_before}
   
__Description and Characterization of Dataset__ 

<p style="text-align:justify;">

In the predictive modeling, machine learning was used to make a predictive model of the dataset. The sequence of this project was as follows: 1. Data selection and clearing 2. Machine learning - 2.1 Normalization and Regularizatioon, 2.2 Perform analysis 2.3 Check the validity. In conclusion, all machine learning techniques were compared in terms of accuracy, speed, and simplicity. 

# {.page_break_before}
__Data selection and coordinate transform__

First, the data was sorted by using the correlation plot. Since there were numerous variables in the dataset, selective dependent variables introduced in the exploratory data analysis section were also used for the machine learning. This contains distance to coast, Impervious 100, Impervious 5000, Impervious 10000, Population 100, Population 5000, Population 10000, Major 100, Major 5000, Major 10000, Residential 100, Residential 5000, Residential 10000, Total 100, Total 5000, Total 10000.

The correlation comparison was segmented into five different groups at first, since to visually inspect, it was impossible to compare all. Also, depending on the naming (i.e. impervious), this process was expected to classify necessary data. Figure 1 shows the results of each correlation plot.

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_1.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 1:</strong> Correlations of each dependent variables</figcaption>
</figure>

As per the correlation plots, it was assumed that as the color of the curves get darker. By comparing all, it was concluded that distance to coast, impervious 100, major 100, major 5000, resident 100, resident 5000, total 100, and total 5000 have less correlation. This was reanalyzed through correlation plotting as shown in figure 2 to be more accurate.

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_2.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 2:</strong> Reanalyze and final correlation checking </figcaption>
</figure>

Finally, Distance to coast, Impervious 100, Major 100, Major 5000, Resident 100, and Resident 5000 were selected as dependent variables. The dataframe consists of 369 rows and 8 columns (including state information and independent variable - Observed NO2 ppb).

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_3.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 3:</strong> Training data </figcaption>
</figure>

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_4.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 4:</strong> Training data </figcaption>
</figure>

Figure 3 is training dataset and figure 4 is testing dataset. As more data are used in analysis, the training gets more accurate. Thus, all state information with pre-selected variables were used for training. After machine learning, each results were compared to the four states information and/or all states information.

# {.page_break_before}
__Machine learning__

Machine learning was performed in five different methods: linear regression, decision tree, k-means clustering, neural network, [].

1. Linear regression
   
The first method used for prediction was linear regression model. This method is quite simple but it would give us a sense of machine learning and the complexity needed for training data. THe dataset shown in Figure 3 was used as a training set and dataset shown in Figure 4 was used as a testing set. Mean squared error was used to minimize the error and in the linear model and independent variable and gradient descent parameter was used in the model structure. The training set was standardized and normalized to enhance the accuracy of prediction. Figure 5 shown the main flow of the coding.

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_5_1.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 5:</strong> Linear regression code flow </figcaption>
</figure>

After training, the dataset was trained as shown in Figure 6. By performing root mean square error, the scoring was 4.3. Still, it is not as low as expected. For future modeling, more dataset could be used for higher accuracy, polymodel rather than linear model can be tried.

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_5.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 6:</strong> Linear regression result </figcaption>
</figure>

2. Decision tree

Decision tree was also used for predicting the dataset. Six variables that were assigned in the dataset selection, each were gini plotted for setting up the baselines. Figure 7 shows the code flow and Figure 8 shows the gini plot with each variable. Dependeing on the ppb value, <10 was decided to be low, >20 was decided to be high, and between that was decided to be medium. These values are the dominant range of ppb level in all states.

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_6_1.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 7:</strong> Decision tree code flow </figcaption>
</figure>

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Pro3_6.jpg?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 8:</strong> Gini plot for six variables </figcaption>
</figure>

With comparing all plots, the cutting points were decided as: 1) Distance to coast (km) > 1500 : low, Distance to coast (km) < 100 : high, Impervious_100 < 20 : low, Impervious 100 > 60 : high, Major 5000 > 200 : high, Major 5000 < 50 : low, Resident 5000 < 200 : low, else : medium (Figure 7).

The model's precision was calculated by measuring recall divided by the average of the prevision and recall, which got value of 0.078. Decision tree method was proven to be quite accurate is classifying NO2 pollutant value in high, medium, and low range.

3.

## 4. Predictive Modeling {.page_break_before}
   
__4.1 Machine learning methods__ 
<p style="text-align:justify;">
In this study, various machine learning models were implemented to predict NO2 concentrations based on different land-use variables. The primary goal was to build a predictive model following different techniques, compare their performances, and understand their strengths and limitations. The process began with a linear regression model, providing a foundation for data analysis and serving as a benchmark for advanced models. This was followed by the implementation of decision tree regression, random forest regressor, and a neural network algorithm. The models were evaluated using metrics like R² and RMSE values. RMSE is a root mean square error, in which the best value is 0 and the worst value is near infinite [7]. R2 is the proportion of the variance in the dependent variable that is predictable from the independent variables [8]. R2 is best when close to 1 and worst in - infinite. Each machine learning method was compared with these criteria to show their effectiveness. This systematic comparison aims to provide insights into the suitability of different algorithms for NO2 modeling based on land use patterns.
</p>


<p style="text-align:justify;">
__4.1.1. Linear regression__  
</p>

<p style="text-align:justify;">
The first method used for machine learning was the linear regression model. Linear regression establishes a straight-line relationship between the independent variables (features) and the dependent variable (NO2 levels) by fitting the data to minimize the root mean squared error. The dataset is standardized to ensure that all features have a mean of zero and a standard deviation of one, which is critical for maintaining balance among variables with different scales. A total of 369 samples are divided into training and testing datasets using an 75/25 split. The code used for generating this linear regression model is shown in the appendix. The R2 value of the developed model was 0.49 and RMSE value was 4.3. Figure 4.1 shows the accuracy of the model by plotting predicted NO2 value against observed NO2 value for test and training dataset.
</p>

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Linear%20Regression.png?raw=true">
    <figcaption><strong>Figure 4.1:</strong> Comparison between the NO2 values predicted from Linear Regression model and the observed NO2 values </figcaption>
</figure>

<p style="text-align:justify;">
__4.1.2. Decision tree regression__
</p>

<p style="text-align:justify;">
A decision tree is a supervised machine learning algorithm used for regression tasks. It predicts the value of a target variable by recursively splitting the dataset based on decision rules derived from feature values. In regression tasks, the splits minimize a loss function, such as the mean squared error (MSE), to ensure that predictions at each leaf node are as close as possible to the actual values. Some critical parameters of this algorithm are:
</p>

<p style="text-align:justify;">  
a) max_depth: It limits the minimum number of samples required to split an internal node. This study considers a depth of 20, which is suitable for capturing the complex land use patterns and correlation with NO2 data without overfitting.
</p>

<p style="text-align:justify;">  
b) min_samples_split: It is the minimum number of samples required to split an internal node. The large values prevent overfitting by avoiding overly specific splits. A value of 2 was considered in the model.
</p>
   
</p><p style="text-align:justify;">  
c) min_samples_leaf: The minimum number of samples required to be at a leaf node ensures that leaf nodes represent significant data, improving model generalization. 
</p>

<p style="text-align:justify;">  
Figure 4.2 shows the result from decision tree regression. Ahe model produced an R² value of -0.0 and an RMSE of 5.55, indicating poor predictive performance and a lack of generalization to unseen data. This suggests that a single decision tree is insufficient for capturing the complexity of the NO₂ dataset, as it is prone to overfitting and underperforming on test data.
</p>

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Decision_regression.png?raw=true" alt="Sample Image">
    <figcaption><strong>Figure 4.2:</strong> Comparison between the NO2 values predicted from Decision Tree Regression and the observed NO2 valuess </figcaption>
</figure>

__4.1.3. Random forest Regressor__
<p style="text-align:justify;">   
The random forest regressor is an ensemble machine learning method that improves prediction accuracy by combining multiple decision trees. Unlike a single decision tree, which is prone to overfitting, random forest aggregates predictions from a set of decision trees to reduce variance and improve generalization. Each tree is trained on a different bootstrapped subset of the data, and at each split, only a random subset of features is considered, making the model robust to noise and irrelevant variables. Key parameters used are: n_trees:200, max_depth: 20, min_samples_split: 15 and min_samples_leaf=10. The model is trained using the DecisionTree package. The accuracy was checked by R2 and RMSE values, which are 0.5 and 3.58, respectively. Figure 4.3 shows the relationship between trained NO2 values and observed NO2 values using Random Forest Regressor model. The procedure for coding is shown in the appendix.
</p>

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Random%20Forest%201.png?raw=true">
    <figcaption><strong>Figure 4.3:</strong> Comparison between the NO2 values predicted from Random Forest Regressor model and the observed NO2 values for all the training and test data.  </figcaption>
</figure>
 
<p style="text-align:justify;"> 
   
__4.1.4 Neural Network Algorithm__
</p>
   
<p style="text-align:justify;">     
A neural network is a computational model inspired by the human brain, consisting of layers of interconnected neurons. It is commonly used to learn patterns and relationships in a dataset. This model has been applied to explore its predictive capability compared to other techniques. 
</p>

<p style="text-align:justify;">  
The main neural network architecture has been defined using the chain structure, which takes 12 features as input and passes them to the first hidden layer. Three hidden layers have been added with 128, 64, and 32 neurons, along with ReLU activation. A dropout of 0.5 has been kept to drop 50% of the neurons randomly to prevent overfitting. A single neuron outputs the predicted NO2 value. For this predictive model, R2 value was 0.6 and RMSE value was 3.12. Figure 4.4 shows the relationship between trained NO2 values and observed NO2 values using neural network model. The procedure for coding is shown in the appendix.
</p>

<figure style="text-align: center;">
    <img src="https://github.com/uiceds/project-team492/blob/main/content/images/Neural%20Network.png?raw=true">
    <figcaption><strong>Figure 4.4:</strong> Comparison between the NO2 values predicted from Neural Network model and the observed NO2 values for all the training and test data. </figcaption>
</figure>


<p style="text-align:justify;"> 
__4.2 Comparison Among Different Predictive Models__
</p>

<p style="text-align:justify;">  
The analysis utilized four predictive modeling techniques to predict NO2 concentrations using a dataset of various land use patterns in different locations across the US. The evaluation metrics of all the predictive models used in the analysis are summarized in the table 4.1 below. The accuracy of the predictive model is as follows: Neural Network model > Random Forest Regression > Linear Regression > Decision Tree Regression. 
</p>
<p style="text-align:justify;"> 
Linear regression provides a baseline for comparison which works well for datasets with strong linear relationship between independent variables and target variable. The R2 value of 0.49 suggests that 49% of the variance in NO2 concentration could be explained by the model. However, it leaves 51% of the variance unexplained suggesting room for improvement. The R2 value of 0.35 and RMSE value of 5.55 in case of decision tree model suggests that it is performing worse than linear regression model. Although decision tree regression is capable of capturing complex non-linear relationship, its tendency to overfit might be the reason of its poor performance. To address this issue, Random Forest regression model was used in the next step to reduce overfitting and improve generalization and leverage ensemble learning. In Random Forest algorithm, it combines the prediction of multiple decision trees to reduce variance and overfitting and at each split, consider a random subset of ffeatures instead of all the features. The advantage of this method is clearly apparent from the obtained high R2 value of 0.54 and lower RMSE value of 3.58 demonstrating its robustness and suitability for modeling. Finally, Neural Network algorithm was employed to build a predictive model and it performed best in capturing complex relationship and patterns in the dataset providing a R2 value of 0.62, explaining 62% of the variance in NO2 concentration. It indicates the superior performance of Neural Network model in capturing non-linear and complex data due to their flexible architecture.
</p>
   
 <p style="text-align:center;">
Table 4.1 Accuracy of each model
</p>

| Sl. No |   Technique of the Predictive Model  | R2 | RMSE |
|:-------|:-------------------------------------|:-----|:---|
|    1   |            Linear Regression         | 0.49 |4.30|
|    2   |        Decision Tree Regression      | 0.35 |5.55|
|    3   |        Random Forest Regression      | 0.54 |3.58| 
|    4   |             Neural Network           | 0.62 |3.12|

<p style="text-align:justify;"> 
Although there is no universal value of R2 and other error metrics to determine the model accuracy, a generally considered good R2 value for NO2 prediction would be in between 0.60-0.80 which is able to explain significant portion of the variability in the dataset. The acceptable R2 value will vary depending on the specific study area, data quality and modeling technique used. For comparison, the general ranges of R2 in previous LUR studies worldwide for NO2 prediction varied within 0.54-0.92 in the existing literature. Considering this range, the performance of our predictive model based on Random Forest regression and Neural Network algorithms falls within the range reported in literature. Therefore, these two models can be used to predict NO2 concentration accurately based on land-use pattern. However, there are still some opportunities to enhance the accuracy of the model which is discussed in the next section. 
</p>

<p style="text-align:justify;"> 
__4.3 Future Plan to Improve Accuracy of the Predictive Models__
</p>
As a next step to improve the accuracy of the models, we will do a more comprehensive feature importance analysis to include only the most relevant predictors simplifying the the model and improving interpretability. We will explore the potential of hyperparameter tuning such as n_trees, max_depth, min_samples_split and min_samples_leaf to improve the accuracy of our decision tree and random forest regression. 
